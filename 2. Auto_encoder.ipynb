{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8618c1",
   "metadata": {},
   "source": [
    "# Autoencoder for ERA5 Climate Data\n",
    "\n",
    "This notebook demonstrates the implementation of an autoencoder neural network for dimensionality reduction and feature learning from ERA5 climate data. The autoencoder compresses high-dimensional meteorological data into a lower-dimensional latent space representation.\n",
    "\n",
    "## Overview\n",
    "- **Input**: ERA5 meteorological variables (252 features = 2 time steps × 14 variables × 9 spatial points)\n",
    "- **Architecture**: Fully connected autoencoder with 32-dimensional latent space\n",
    "- **Objective**: Learn compressed representations while maintaining reconstruction quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93956267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e18f8a6",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Preprocessing\n",
    "\n",
    "## 1.1 Dataset Description\n",
    "The dataset contains ERA5 reanalysis data with the following structure:\n",
    "- **Meteorological variables**: u10, v10, d2m, t2m, msl, sst, skt, sp, ssrd, strd, tp (11 variables)\n",
    "- **Wave variables**: mwd, mwp, swh (3 variables)\n",
    "- **Total features per sample**: 252 (2 time steps × 14 variables × 9 spatial points)\n",
    "- **Training samples**: 10,000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57623a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (14, 105, 6624)\n",
      "Variables: ['u10', 'v10', 'd2m', 't2m', 'msl', 'sst', 'skt', 'sp', 'ssrd', 'strd', 'tp', 'mwd', 'mwp', 'swh']\n",
      "Progress: |==============================| 10000/10000 (100.0%)Initial input shape: torch.Size([10000, 252])\n",
      "Progress: |==============================| 2000/2000 (100.0%)\n",
      " Final input shape: torch.Size([10000, 252])\n",
      "Features per sample: 252 (time_steps=2 × spatial_points=9 × variables=14)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from training folder\n",
    "ds_train = xr.open_dataset(\"dataset_train/combined.nc\")\n",
    "\n",
    "# Define meteorological and wave variables\n",
    "variables = [\"u10\", \"v10\", \"d2m\", \"t2m\", \"msl\", \"sst\", \"skt\", \"sp\", \"ssrd\", \"strd\", \"tp\", \"mwd\", \"mwp\", \"swh\"]\n",
    "Xs = ds_train[variables].to_array().values\n",
    "\n",
    "print(f\"Dataset shape: {Xs.shape}\")\n",
    "print(f\"Variables: {variables}\")\n",
    "\n",
    "# Generate training data with specified parameters\n",
    "n_data_train = 10000  # Number of samples\n",
    "neigh_lat, neigh_lon = 1, 1  # Spatial neighborhood size (3x3 grid)\n",
    "time_horizon = 2  # Number of time steps\n",
    "\n",
    "from GetData import get_train_data\n",
    "train_data = np.array(get_train_data(ds_train, Xs, n_data_train, neigh_lat=neigh_lat, neigh_lon=neigh_lon, time_horizon=time_horizon)[0])\n",
    "X = torch.tensor(train_data, dtype=torch.float32)\n",
    "print(f\"Initial input shape: {X.shape}\")\n",
    "\n",
    "n_data_test = 2000  # Number of test samples\n",
    "ds_test = xr.open_dataset(\"dataset_test/combined.nc\")\n",
    "\n",
    "test_data = np.array(get_train_data(ds_test, Xs, n_data_test, neigh_lat=neigh_lat, neigh_lon=neigh_lon, time_horizon=time_horizon)[0])\n",
    "X_test = torch.tensor(test_data, dtype=torch.float32)\n",
    "X_test = X_test.reshape(-1, time_horizon * 9 * len(variables))  # (samples, 252 features)\n",
    "\n",
    "print(f\"\\n Final input shape: {X.shape}\")\n",
    "print(f\"Features per sample: {X.shape[1]} (time_steps={time_horizon} × spatial_points=9 × variables={len(variables)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b63769",
   "metadata": {},
   "source": [
    "## 1.2 Data Normalization\n",
    "Standardize the input features to improve training stability and convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dfb13d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After normalization:\n",
      "Mean: 0.000000, Std: 1.000\n",
      "Min: -6.242, Max: 53.970\n"
     ]
    }
   ],
   "source": [
    "# Standardize features (zero mean, unit variance)\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "print(f\"After normalization:\")\n",
    "print(f\"Mean: {X_normalized.mean():.6f}, Std: {X_normalized.std():.3f}\")\n",
    "print(f\"Min: {X_normalized.min():.3f}, Max: {X_normalized.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc06b73c",
   "metadata": {},
   "source": [
    "# 2. Autoencoder Model Architecture\n",
    "\n",
    "## 2.1 Model Definition\n",
    "The autoencoder consists of:\n",
    "- **Encoder**: Compresses 252D input → 128D → 32D latent space\n",
    "- **Decoder**: Reconstructs 32D latent → 128D → 252D output\n",
    "- **Activation**: ReLU activations for non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f082dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Autoencoder Architecture:\n",
      "Input dimension: 252\n",
      "Hidden dimension: 128\n",
      "Latent dimension: 32\n",
      "Compression ratio: 7.9:1\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully connected autoencoder for dimensionality reduction.\n",
    "    \n",
    "    Args:\n",
    "        input_dim (int): Input feature dimension (252)\n",
    "        latent_dim (int): Latent space dimension (32)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder: input_dim → 128 → latent_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder: latent_dim → 128 → input_dim\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)  # No activation for continuous output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through encoder and decoder\"\"\"\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Get latent representation\"\"\"\n",
    "        return self.encoder(x)\n",
    "\n",
    "# Model parameters\n",
    "INPUT_DIM = X.shape[1]  # 252\n",
    "LATENT_DIM = 32\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "print(f\"Model Autoencoder Architecture:\")\n",
    "print(f\"Input dimension: {INPUT_DIM}\")\n",
    "print(f\"Hidden dimension: {HIDDEN_DIM}\")\n",
    "print(f\"Latent dimension: {LATENT_DIM}\")\n",
    "print(f\"Compression ratio: {INPUT_DIM/LATENT_DIM:.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1c478b",
   "metadata": {},
   "source": [
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ca8983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda\n",
      "\n",
      "Starting training for 500 epochs...\n",
      "Epoch [  1/500] - Loss: 0.615497\n",
      "Epoch [ 50/500] - Loss: 0.010427\n",
      "Epoch [100/500] - Loss: 0.006926\n",
      "Epoch [150/500] - Loss: 0.005710\n",
      "Epoch [200/500] - Loss: 0.005403\n",
      "Epoch [250/500] - Loss: 0.005212\n",
      "Epoch [300/500] - Loss: 0.005351\n",
      "Epoch [350/500] - Loss: 0.005089\n",
      "Epoch [400/500] - Loss: 0.005025\n",
      "Epoch [450/500] - Loss: 0.004959\n",
      "Epoch [500/500] - Loss: 0.004865\n"
     ]
    }
   ],
   "source": [
    "# 3. Model Training\n",
    "\n",
    "## Training Configuration\n",
    "EPOCHS = 500\n",
    "LEARNING_RATE = 0.0002\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Setup device and model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = Autoencoder(INPUT_DIM, LATENT_DIM, HIDDEN_DIM).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# Prepare data loader\n",
    "\n",
    "X_tensor = torch.tensor(X_normalized, dtype=torch.float32)\n",
    "train_loader = DataLoader(TensorDataset(X_tensor), batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Training loop with progress tracking\n",
    "model.train()\n",
    "train_losses = []\n",
    "\n",
    "print(f\"\\nStarting training for {EPOCHS} epochs...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        data = batch[0].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed = model(data)\n",
    "        loss = criterion(reconstructed, data)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Record average loss for epoch\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 50 == 0 or epoch == 0:\n",
    "        print(f\"Epoch [{epoch+1:3d}/{EPOCHS}] - Loss: {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce36531",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation and Visualization\n",
    "\n",
    "## 4.1 Generate Reconstructions\n",
    "Evaluate the trained model on the training data to assess reconstruction quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6b3e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (2000, 252)\n",
      "Latent representations shape: (2000, 32)\n",
      "Reconstructed data shape: (2000, 252)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate reconstructions and latent representations\n",
    "model.eval()\n",
    "X_test_tensor = torch.tensor(X_test_normalized, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = X_test_tensor.to(device)  # Move X_test_tensor to the same device as the model\n",
    "    reconstructed = model(X_test_tensor).cpu().numpy()\n",
    "    latent_representations = model.encode(X_test_tensor).cpu().numpy()\n",
    "\n",
    "print(f\"Original data shape: {X_test_normalized.shape}\")\n",
    "print(f\"Latent representations shape: {latent_representations.shape}\")\n",
    "print(f\"Reconstructed data shape: {reconstructed.shape}\")\n",
    "\n",
    "# Visualize samples in different representations\n",
    "n_samples = 4\n",
    "fig, axes = plt.subplots(3, n_samples, figsize=(15, 8))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Original (normalized)\n",
    "    axes[0, i].imshow(X_test_normalized[i].reshape(18, 14), cmap='gray')\n",
    "    axes[0, i].set_title(f'Original Sample {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Latent representation (32D → 8x4 for visualization)\n",
    "    axes[1, i].imshow(latent_representations[i].reshape(8, 4), cmap='gray')\n",
    "    axes[1, i].set_title(f'Latent (32D)')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Reconstructed\n",
    "    axes[2, i].imshow(reconstructed[i].reshape(18, 14), cmap='gray')\n",
    "    axes[2, i].set_title(f'Reconstructed')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.suptitle('Autoencoder Results: Original → Latent → Reconstructed', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e7e8f",
   "metadata": {},
   "source": [
    "## 4.2 Quantitative Evaluation\n",
    "Reconstruction Error per Feature: in original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2479a32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 252)\n",
      "\n",
      "Reconstruction Error per Feature: in original scale\n",
      "   Feature                  MSE                NRMSE\n",
      "         1               0.2175               0.0895\n",
      "         2               0.3738               0.1217\n",
      "         3               0.1856               0.1223\n",
      "         4               0.0381               0.0692\n",
      "         5            1620.6250               0.0639\n",
      "         6               0.0251               0.0634\n",
      "         7               0.0246               0.0626\n",
      "         8            1630.6396               0.0641\n",
      "         9      8527065600.0000               0.0900\n",
      "        10       500907392.0000               0.2411\n",
      "        11               0.0000               0.3163\n",
      "        12             549.3501               0.1824\n",
      "        13               0.0235               0.1016\n",
      "        14               0.0102               0.0871\n",
      "        15               0.1445               0.0731\n",
      "        16               0.3303               0.1145\n",
      "        17               0.1859               0.1226\n",
      "        18               0.0298               0.0612\n",
      "        19            1148.1702               0.0539\n",
      "        20               0.0229               0.0608\n",
      "        21               0.0244               0.0626\n",
      "        22            1215.9905               0.0555\n",
      "        23      7725958656.0000               0.0858\n",
      "        24       229961680.0000               0.1637\n",
      "        25               0.0000               0.3095\n",
      "        26             522.7352               0.1778\n",
      "        27               0.0208               0.0953\n",
      "        28               0.0074               0.0751\n",
      "        29               0.1815               0.0819\n",
      "        30               0.3915               0.1245\n",
      "        31               0.1714               0.1174\n",
      "        32               0.0317               0.0631\n",
      "        33            1265.7743               0.0570\n",
      "        34               0.0286               0.0682\n",
      "        35               0.0331               0.0733\n",
      "        36            1522.2849               0.0625\n",
      "        37      7053357056.0000               0.0819\n",
      "        38       352735936.0000               0.2030\n",
      "        39               0.0000               0.2501\n",
      "        40             247.2955               0.1218\n",
      "        41               0.0181               0.0889\n",
      "        42               0.0057               0.0660\n",
      "        43               0.2047               0.0871\n",
      "        44               0.3812               0.1219\n",
      "        45               0.1373               0.1047\n",
      "        46               0.0275               0.0582\n",
      "        47            1575.0382               0.0620\n",
      "        48               0.0226               0.0587\n",
      "        49               0.0230               0.0591\n",
      "        50            1561.7842               0.0617\n",
      "        51      6046458368.0000               0.0759\n",
      "        52       225766688.0000               0.1604\n",
      "        53               0.0000               0.3411\n",
      "        54             513.8151               0.1792\n",
      "        55               0.0191               0.0918\n",
      "        56               0.0084               0.0794\n",
      "        57               0.1452               0.0731\n",
      "        58               0.3189               0.1113\n",
      "        59               0.1027               0.0903\n",
      "        60               0.0187               0.0479\n",
      "        61             961.2972               0.0487\n",
      "        62               0.0163               0.0500\n",
      "        63               0.0192               0.0544\n",
      "        64             990.8456               0.0495\n",
      "        65      5240920576.0000               0.0706\n",
      "        66       361876448.0000               0.2034\n",
      "        67               0.0000               0.4285\n",
      "        68             271.3208               0.1298\n",
      "        69               0.0141               0.0789\n",
      "        70               0.0046               0.0593\n",
      "        71               0.2450               0.0953\n",
      "        72               0.4152               0.1271\n",
      "        73               0.1603               0.1126\n",
      "        74               0.0299               0.0606\n",
      "        75            2011.7606               0.0710\n",
      "        76               0.0233               0.0600\n",
      "        77               0.0302               0.0683\n",
      "        78            1967.3687               0.0702\n",
      "        79      6969635328.0000               0.0810\n",
      "        80       322168864.0000               0.1925\n",
      "        81               0.0000               0.4038\n",
      "        82             542.6677               0.1825\n",
      "        83               0.0187               0.0911\n",
      "        84               0.0073               0.0738\n",
      "        85               0.2432               0.0947\n",
      "        86               0.3802               0.1202\n",
      "        87               0.1246               0.0990\n",
      "        88               0.0291               0.0591\n",
      "        89            1263.0385               0.0548\n",
      "        90               0.0340               0.0700\n",
      "        91               0.0330               0.0689\n",
      "        92            1274.2789               0.0550\n",
      "        93      8473121280.0000               0.0898\n",
      "        94       381722176.0000               0.2065\n",
      "        95               0.0000               0.2439\n",
      "        96             410.2282               0.1624\n",
      "        97               0.0183               0.0905\n",
      "        98               0.0060               0.0671\n",
      "        99               0.2549               0.0973\n",
      "       100               0.3886               0.1216\n",
      "       101               0.1596               0.1118\n",
      "       102               0.0274               0.0574\n",
      "       103            1368.7616               0.0574\n",
      "       104               0.0264               0.0618\n",
      "       105               0.0317               0.0678\n",
      "       106            1387.9183               0.0578\n",
      "       107      8988035072.0000               0.0923\n",
      "       108       347780352.0000               0.1977\n",
      "       109               0.0000               0.4849\n",
      "       110             381.4897               0.1557\n",
      "       111               0.0184               0.0911\n",
      "       112               0.0071               0.0726\n",
      "       113               0.2810               0.1017\n",
      "       114               0.4592               0.1326\n",
      "       115               0.2088               0.1284\n",
      "       116               0.0351               0.0652\n",
      "       117            2322.8589               0.0750\n",
      "       118               0.0294               0.0655\n",
      "       119               0.0394               0.0758\n",
      "       120            2206.4016               0.0731\n",
      "       121     10683233280.0000               0.1004\n",
      "       122       681089152.0000               0.2773\n",
      "       123               0.0000               0.3283\n",
      "       124             416.3646               0.1616\n",
      "       125               0.0218               0.0988\n",
      "       126               0.0115               0.0920\n",
      "       127               0.3048               0.1062\n",
      "       128               0.3616               0.1201\n",
      "       129               0.1571               0.1129\n",
      "       130               0.0272               0.0584\n",
      "       131            1776.3560               0.0670\n",
      "       132               0.0241               0.0622\n",
      "       133               0.0283               0.0672\n",
      "       134            1731.1052               0.0661\n",
      "       135      8290612736.0000               0.0889\n",
      "       136       530439968.0000               0.2495\n",
      "       137               0.0000               0.2487\n",
      "       138             564.4957               0.1848\n",
      "       139               0.0205               0.0950\n",
      "       140               0.0094               0.0836\n",
      "       141               0.2222               0.0908\n",
      "       142               0.2618               0.1022\n",
      "       143               0.1377               0.1056\n",
      "       144               0.0235               0.0544\n",
      "       145            1172.5059               0.0546\n",
      "       146               0.0253               0.0640\n",
      "       147               0.0252               0.0637\n",
      "       148            1296.8737               0.0574\n",
      "       149      8542932480.0000               0.0902\n",
      "       150       253431120.0000               0.1707\n",
      "       151               0.0000               0.2197\n",
      "       152             464.5358               0.1673\n",
      "       153               0.0142               0.0786\n",
      "       154               0.0056               0.0649\n",
      "       155               0.2221               0.0907\n",
      "       156               0.3766               0.1222\n",
      "       157               0.1390               0.1057\n",
      "       158               0.0246               0.0557\n",
      "       159            1101.7372               0.0532\n",
      "       160               0.0278               0.0672\n",
      "       161               0.0311               0.0709\n",
      "       162            1131.1202               0.0540\n",
      "       163      7544137728.0000               0.0847\n",
      "       164       358927648.0000               0.2019\n",
      "       165               0.0000               0.1598\n",
      "       166             329.6384               0.1400\n",
      "       167               0.0119               0.0722\n",
      "       168               0.0042               0.0564\n",
      "       169               0.2231               0.0910\n",
      "       170               0.2928               0.1069\n",
      "       171               0.1405               0.1059\n",
      "       172               0.0256               0.0561\n",
      "       173            1817.4006               0.0667\n",
      "       174               0.0232               0.0595\n",
      "       175               0.0227               0.0587\n",
      "       176            1863.1591               0.0675\n",
      "       177      6550185472.0000               0.0791\n",
      "       178       250057184.0000               0.1682\n",
      "       179               0.0000               0.2867\n",
      "       180             544.5588               0.1841\n",
      "       181               0.0173               0.0873\n",
      "       182               0.0074               0.0744\n",
      "       183               0.1435               0.0729\n",
      "       184               0.2870               0.1056\n",
      "       185               0.1091               0.0931\n",
      "       186               0.0203               0.0500\n",
      "       187             984.0538               0.0494\n",
      "       188               0.0163               0.0501\n",
      "       189               0.0183               0.0530\n",
      "       190            1007.7806               0.0499\n",
      "       191      5780075008.0000               0.0742\n",
      "       192       377114784.0000               0.2053\n",
      "       193               0.0000               0.4417\n",
      "       194             304.2555               0.1370\n",
      "       195               0.0133               0.0769\n",
      "       196               0.0047               0.0599\n",
      "       197               0.2356               0.0939\n",
      "       198               0.4545               0.1333\n",
      "       199               0.1526               0.1101\n",
      "       200               0.0359               0.0666\n",
      "       201            1661.6202               0.0646\n",
      "       202               0.0292               0.0673\n",
      "       203               0.0288               0.0667\n",
      "       204            1699.7260               0.0653\n",
      "       205      7410268672.0000               0.0837\n",
      "       206       326700640.0000               0.1919\n",
      "       207               0.0000               0.3428\n",
      "       208             568.6406               0.1866\n",
      "       209               0.0192               0.0924\n",
      "       210               0.0078               0.0764\n",
      "       211               0.1733               0.0802\n",
      "       212               0.3569               0.1165\n",
      "       213               0.1605               0.1123\n",
      "       214               0.0323               0.0624\n",
      "       215            1572.6433               0.0612\n",
      "       216               0.0339               0.0699\n",
      "       217               0.0332               0.0692\n",
      "       218            1509.3541               0.0600\n",
      "       219      8257494016.0000               0.0888\n",
      "       220       386088480.0000               0.2066\n",
      "       221               0.0000               0.2245\n",
      "       222             300.5391               0.1387\n",
      "       223               0.0224               0.1003\n",
      "       224               0.0079               0.0769\n",
      "       225               0.1861               0.0835\n",
      "       226               0.4554               0.1318\n",
      "       227               0.1938               0.1235\n",
      "       228               0.0362               0.0661\n",
      "       229            1272.3550               0.0554\n",
      "       230               0.0269               0.0625\n",
      "       231               0.0294               0.0653\n",
      "       232            1330.4744               0.0567\n",
      "       233      8660280320.0000               0.0909\n",
      "       234       340879328.0000               0.1951\n",
      "       235               0.0000               0.4871\n",
      "       236             491.6754               0.1762\n",
      "       237               0.0243               0.1046\n",
      "       238               0.0085               0.0794\n",
      "       239               0.3005               0.1054\n",
      "       240               0.5181               0.1412\n",
      "       241               0.2432               0.1386\n",
      "       242               0.0459               0.0746\n",
      "       243            1930.1501               0.0685\n",
      "       244               0.0314               0.0676\n",
      "       245               0.0366               0.0730\n",
      "       246            1866.8286               0.0674\n",
      "       247     10452153344.0000               0.0997\n",
      "       248       657382656.0000               0.2718\n",
      "       249               0.0000               0.3766\n",
      "       250             470.3467               0.1717\n",
      "       251               0.0295               0.1150\n",
      "       252               0.0128               0.0972\n",
      "Mean NRMSE:  0.11290962 Max NRMSE:  0.48711056\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE per feature\n",
    "reconstructed_inv = scaler.inverse_transform(reconstructed)\n",
    "X_test_numpy = X_test.cpu().numpy()  # Convert X_test (Tensor) to NumPy array\n",
    "reconstructed_mse = np.mean((reconstructed_inv - X_test_numpy) ** 2, axis=0)\n",
    "reconstructed_nrmse = np.sqrt(reconstructed_mse) / np.std(X_test_numpy, axis=0)\n",
    "print(reconstructed_inv.shape)\n",
    "print(f\"\\nReconstruction Error per Feature: in original scale\")\n",
    "print(f\"{'Feature':>10} {'MSE':>20} {'NRMSE':>20}\")\n",
    "for i in range(0, len(reconstructed_mse), 1):  # Sample every 20th feature\n",
    "    print(f\"{i+1:>10} {reconstructed_mse[i]:>20.4f} {reconstructed_nrmse[i]:>20.4f}\")\n",
    "\n",
    "print(\"Mean NRMSE: \", np.mean(reconstructed_nrmse), \"Max NRMSE: \", np.max(reconstructed_nrmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e9d9e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reconstruction Error per Feature: in normalized scale\n",
      "   Feature                  MSE                NRMSE\n",
      "         1               0.0086               0.0895\n",
      "         2               0.0112               0.1217\n",
      "         3               0.0118               0.1223\n",
      "         4               0.0038               0.0692\n",
      "         5               0.0027               0.0639\n",
      "         6               0.0030               0.0634\n",
      "         7               0.0029               0.0626\n",
      "         8               0.0028               0.0641\n",
      "         9               0.0088               0.0900\n",
      "        10               0.0503               0.2411\n",
      "        11               0.0362               0.3163\n",
      "        12               0.0469               0.1824\n",
      "        13               0.0097               0.1016\n",
      "        14               0.0057               0.0871\n",
      "        15               0.0057               0.0731\n",
      "        16               0.0099               0.1145\n",
      "        17               0.0119               0.1226\n",
      "        18               0.0030               0.0612\n",
      "        19               0.0019               0.0539\n",
      "        20               0.0027               0.0608\n",
      "        21               0.0029               0.0626\n",
      "        22               0.0021               0.0555\n",
      "        23               0.0080               0.0858\n",
      "        24               0.0232               0.1637\n",
      "        25               0.0448               0.3095\n",
      "        26               0.0445               0.1778\n",
      "        27               0.0085               0.0953\n",
      "        28               0.0042               0.0751\n",
      "        29               0.0072               0.0819\n",
      "        30               0.0117               0.1245\n",
      "        31               0.0110               0.1174\n",
      "        32               0.0032               0.0631\n",
      "        33               0.0022               0.0570\n",
      "        34               0.0034               0.0682\n",
      "        35               0.0039               0.0733\n",
      "        36               0.0026               0.0625\n",
      "        37               0.0073               0.0819\n",
      "        38               0.0355               0.2030\n",
      "        39               0.0236               0.2501\n",
      "        40               0.0210               0.1218\n",
      "        41               0.0074               0.0889\n",
      "        42               0.0032               0.0660\n",
      "        43               0.0081               0.0871\n",
      "        44               0.0112               0.1219\n",
      "        45               0.0086               0.1047\n",
      "        46               0.0027               0.0582\n",
      "        47               0.0026               0.0620\n",
      "        48               0.0026               0.0587\n",
      "        49               0.0027               0.0591\n",
      "        50               0.0026               0.0617\n",
      "        51               0.0063               0.0759\n",
      "        52               0.0222               0.1604\n",
      "        53               0.0472               0.3411\n",
      "        54               0.0454               0.1792\n",
      "        55               0.0079               0.0918\n",
      "        56               0.0046               0.0794\n",
      "        57               0.0058               0.0731\n",
      "        58               0.0094               0.1113\n",
      "        59               0.0064               0.0903\n",
      "        60               0.0018               0.0479\n",
      "        61               0.0016               0.0487\n",
      "        62               0.0019               0.0500\n",
      "        63               0.0022               0.0544\n",
      "        64               0.0016               0.0495\n",
      "        65               0.0054               0.0706\n",
      "        66               0.0358               0.2034\n",
      "        67               0.0712               0.4285\n",
      "        68               0.0238               0.1298\n",
      "        69               0.0058               0.0789\n",
      "        70               0.0026               0.0593\n",
      "        71               0.0098               0.0953\n",
      "        72               0.0122               0.1271\n",
      "        73               0.0101               0.1126\n",
      "        74               0.0029               0.0606\n",
      "        75               0.0033               0.0710\n",
      "        76               0.0027               0.0600\n",
      "        77               0.0035               0.0683\n",
      "        78               0.0033               0.0702\n",
      "        79               0.0072               0.0810\n",
      "        80               0.0318               0.1925\n",
      "        81               0.0411               0.4038\n",
      "        82               0.0475               0.1825\n",
      "        83               0.0077               0.0911\n",
      "        84               0.0041               0.0738\n",
      "        85               0.0097               0.0947\n",
      "        86               0.0110               0.1202\n",
      "        87               0.0076               0.0990\n",
      "        88               0.0028               0.0591\n",
      "        89               0.0020               0.0548\n",
      "        90               0.0039               0.0700\n",
      "        91               0.0038               0.0689\n",
      "        92               0.0020               0.0550\n",
      "        93               0.0089               0.0898\n",
      "        94               0.0368               0.2065\n",
      "        95               0.0266               0.2439\n",
      "        96               0.0376               0.1624\n",
      "        97               0.0076               0.0905\n",
      "        98               0.0033               0.0671\n",
      "        99               0.0102               0.0973\n",
      "       100               0.0112               0.1216\n",
      "       101               0.0098               0.1118\n",
      "       102               0.0026               0.0574\n",
      "       103               0.0022               0.0574\n",
      "       104               0.0030               0.0618\n",
      "       105               0.0037               0.0678\n",
      "       106               0.0022               0.0578\n",
      "       107               0.0094               0.0923\n",
      "       108               0.0337               0.1977\n",
      "       109               0.0485               0.4849\n",
      "       110               0.0347               0.1557\n",
      "       111               0.0077               0.0911\n",
      "       112               0.0039               0.0726\n",
      "       113               0.0113               0.1017\n",
      "       114               0.0132               0.1326\n",
      "       115               0.0129               0.1284\n",
      "       116               0.0034               0.0652\n",
      "       117               0.0037               0.0750\n",
      "       118               0.0034               0.0655\n",
      "       119               0.0045               0.0758\n",
      "       120               0.0035               0.0731\n",
      "       121               0.0112               0.1004\n",
      "       122               0.0659               0.2773\n",
      "       123               0.0224               0.3283\n",
      "       124               0.0377               0.1616\n",
      "       125               0.0090               0.0988\n",
      "       126               0.0064               0.0920\n",
      "       127               0.0120               0.1062\n",
      "       128               0.0108               0.1201\n",
      "       129               0.0100               0.1129\n",
      "       130               0.0027               0.0584\n",
      "       131               0.0030               0.0670\n",
      "       132               0.0029               0.0622\n",
      "       133               0.0034               0.0672\n",
      "       134               0.0029               0.0661\n",
      "       135               0.0085               0.0889\n",
      "       136               0.0532               0.2495\n",
      "       137               0.0239               0.2487\n",
      "       138               0.0482               0.1848\n",
      "       139               0.0085               0.0950\n",
      "       140               0.0052               0.0836\n",
      "       141               0.0088               0.0908\n",
      "       142               0.0078               0.1022\n",
      "       143               0.0088               0.1056\n",
      "       144               0.0023               0.0544\n",
      "       145               0.0020               0.0546\n",
      "       146               0.0030               0.0640\n",
      "       147               0.0030               0.0637\n",
      "       148               0.0022               0.0574\n",
      "       149               0.0088               0.0902\n",
      "       150               0.0255               0.1707\n",
      "       151               0.0156               0.2197\n",
      "       152               0.0395               0.1673\n",
      "       153               0.0058               0.0786\n",
      "       154               0.0031               0.0649\n",
      "       155               0.0088               0.0907\n",
      "       156               0.0112               0.1222\n",
      "       157               0.0089               0.1057\n",
      "       158               0.0025               0.0557\n",
      "       159               0.0019               0.0532\n",
      "       160               0.0033               0.0672\n",
      "       161               0.0037               0.0709\n",
      "       162               0.0019               0.0540\n",
      "       163               0.0078               0.0847\n",
      "       164               0.0359               0.2019\n",
      "       165               0.0094               0.1598\n",
      "       166               0.0279               0.1400\n",
      "       167               0.0049               0.0722\n",
      "       168               0.0023               0.0564\n",
      "       169               0.0089               0.0910\n",
      "       170               0.0086               0.1069\n",
      "       171               0.0088               0.1059\n",
      "       172               0.0025               0.0561\n",
      "       173               0.0030               0.0667\n",
      "       174               0.0027               0.0595\n",
      "       175               0.0027               0.0587\n",
      "       176               0.0031               0.0675\n",
      "       177               0.0068               0.0791\n",
      "       178               0.0247               0.1682\n",
      "       179               0.0259               0.2867\n",
      "       180               0.0481               0.1841\n",
      "       181               0.0072               0.0873\n",
      "       182               0.0041               0.0744\n",
      "       183               0.0057               0.0729\n",
      "       184               0.0084               0.1056\n",
      "       185               0.0068               0.0931\n",
      "       186               0.0020               0.0500\n",
      "       187               0.0016               0.0494\n",
      "       188               0.0019               0.0501\n",
      "       189               0.0021               0.0530\n",
      "       190               0.0017               0.0499\n",
      "       191               0.0060               0.0742\n",
      "       192               0.0372               0.2053\n",
      "       193               0.0611               0.4417\n",
      "       194               0.0268               0.1370\n",
      "       195               0.0055               0.0769\n",
      "       196               0.0026               0.0599\n",
      "       197               0.0094               0.0939\n",
      "       198               0.0134               0.1333\n",
      "       199               0.0096               0.1101\n",
      "       200               0.0035               0.0666\n",
      "       201               0.0027               0.0646\n",
      "       202               0.0034               0.0673\n",
      "       203               0.0034               0.0667\n",
      "       204               0.0028               0.0653\n",
      "       205               0.0077               0.0837\n",
      "       206               0.0321               0.1919\n",
      "       207               0.0327               0.3428\n",
      "       208               0.0498               0.1866\n",
      "       209               0.0079               0.0924\n",
      "       210               0.0044               0.0764\n",
      "       211               0.0069               0.0802\n",
      "       212               0.0104               0.1165\n",
      "       213               0.0098               0.1123\n",
      "       214               0.0031               0.0624\n",
      "       215               0.0025               0.0612\n",
      "       216               0.0039               0.0699\n",
      "       217               0.0038               0.0692\n",
      "       218               0.0024               0.0600\n",
      "       219               0.0086               0.0888\n",
      "       220               0.0375               0.2066\n",
      "       221               0.0205               0.2245\n",
      "       222               0.0276               0.1387\n",
      "       223               0.0093               0.1003\n",
      "       224               0.0043               0.0769\n",
      "       225               0.0075               0.0835\n",
      "       226               0.0132               0.1318\n",
      "       227               0.0119               0.1235\n",
      "       228               0.0035               0.0661\n",
      "       229               0.0020               0.0554\n",
      "       230               0.0031               0.0625\n",
      "       231               0.0034               0.0653\n",
      "       232               0.0021               0.0567\n",
      "       233               0.0090               0.0909\n",
      "       234               0.0330               0.1951\n",
      "       235               0.0500               0.4871\n",
      "       236               0.0451               0.1762\n",
      "       237               0.0101               0.1046\n",
      "       238               0.0047               0.0794\n",
      "       239               0.0121               0.1054\n",
      "       240               0.0150               0.1412\n",
      "       241               0.0150               0.1386\n",
      "       242               0.0045               0.0746\n",
      "       243               0.0031               0.0685\n",
      "       244               0.0036               0.0676\n",
      "       245               0.0042               0.0730\n",
      "       246               0.0030               0.0674\n",
      "       247               0.0109               0.0997\n",
      "       248               0.0634               0.2718\n",
      "       249               0.0428               0.3766\n",
      "       250               0.0428               0.1717\n",
      "       251               0.0122               0.1150\n",
      "       252               0.0071               0.0972\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE per feature\n",
    "reconstructed_mse = np.mean((reconstructed - X_test_normalized) ** 2, axis=0)\n",
    "reconstructed_nrmse = np.sqrt(reconstructed_mse) / np.std(X_test_normalized, axis=0)\n",
    "\n",
    "print(f\"\\nReconstruction Error per Feature: in normalized scale\")\n",
    "print(f\"{'Feature':>10} {'MSE':>20} {'NRMSE':>20}\")\n",
    "for i in range(0, len(reconstructed_mse), 1):  # Sample every 20th feature\n",
    "    print(f\"{i+1:>10} {reconstructed_mse[i]:>20.4f} {reconstructed_nrmse[i]:>20.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7e9833",
   "metadata": {},
   "source": [
    "# 5. Model Saving\n",
    "\n",
    "## 5.1 Save Trained Model and Scaler\n",
    "Save the trained autoencoder and data scaler for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be72f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to 'model/scaler.save'\n",
      "Model saved to 'model/autoencoder_model.pth'\n"
     ]
    }
   ],
   "source": [
    "# Save model and preprocessing components\n",
    "SAVE_MODEL = False\n",
    "\n",
    "if SAVE_MODEL:\n",
    "    import joblib\n",
    "    import os\n",
    "    \n",
    "    # Create model directory if it doesn't exist\n",
    "    os.makedirs('model', exist_ok=True)\n",
    "    \n",
    "    # Save the scaler\n",
    "    joblib.dump(scaler, 'model/scaler.save')\n",
    "    print(\"Scaler saved to 'model/scaler.save'\")\n",
    "    \n",
    "    # Save the model state dictionary\n",
    "    torch.save(model.state_dict(), 'model/autoencoder_model.pth')\n",
    "    print(\"Model saved to 'model/autoencoder_model.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
